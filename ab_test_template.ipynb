{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e176dbee",
   "metadata": {},
   "source": [
    "# ðŸ“Š AB Test Template: From Raw Data to Power BI Dashboard\n",
    "\n",
    "This notebook demonstrates the complete workflow from raw data collection to statistical analysis and Power BI visualization.\n",
    "\n",
    "## ðŸŽ¯ What This Template Covers\n",
    "\n",
    "1. **Raw Data Generation** - Realistic AB test data simulation\n",
    "2. **Data Preprocessing** - Cleaning and preparation\n",
    "3. **Statistical Analysis** - Comprehensive AB test analysis  \n",
    "4. **Power BI Export** - Structured data for dashboards\n",
    "5. **Visualization Guidelines** - Power BI dashboard templates\n",
    "\n",
    "## ðŸ“‹ Sample Scenario\n",
    "\n",
    "**Company:** E-commerce website  \n",
    "**Test:** New checkout button design vs. current design  \n",
    "**Metric:** Conversion rate (purchases/visitors)  \n",
    "**Duration:** 14 days  \n",
    "**Traffic Split:** 50/50  \n",
    "\n",
    "Let's build this step by step!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7087a8",
   "metadata": {},
   "source": [
    "## ðŸ“š Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd60ede1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All libraries imported successfully!\n",
      "ðŸ“Š Ready for AB Test Analysis Template\n"
     ]
    }
   ],
   "source": [
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind, chi2_contingency, norm, beta\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure visualization styles\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(\"ðŸ“Š Ready for AB Test Analysis Template\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d4487d",
   "metadata": {},
   "source": [
    "## ðŸŽ² Step 2: Generate Realistic Sample Data\n",
    "\n",
    "This simulates raw data collection from a real AB test scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "018bd0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ² Generating realistic AB test data...\n",
      "âœ… Generated 10,131 user records over 14 days\n",
      "ðŸ“Š Data shape: (10131, 12)\n",
      "ðŸ·ï¸ Groups: {np.str_('Treatment'): 5068, np.str_('Control'): 5063}\n",
      "\n",
      "ðŸ“‹ Sample Data:\n",
      "        user_id           timestamp        date day_of_week      group  \\\n",
      "0  user_00_0000 2025-10-15 22:42:00  2025-10-15   Wednesday    Control   \n",
      "1  user_00_0001 2025-10-15 19:20:00  2025-10-15   Wednesday  Treatment   \n",
      "2  user_00_0002 2025-10-15 21:46:00  2025-10-15   Wednesday    Control   \n",
      "3  user_00_0003 2025-10-15 12:01:00  2025-10-15   Wednesday  Treatment   \n",
      "4  user_00_0004 2025-10-15 21:05:00  2025-10-15   Wednesday  Treatment   \n",
      "5  user_00_0005 2025-10-15 19:59:00  2025-10-15   Wednesday    Control   \n",
      "6  user_00_0006 2025-10-15 15:34:00  2025-10-15   Wednesday    Control   \n",
      "7  user_00_0007 2025-10-15 18:34:00  2025-10-15   Wednesday  Treatment   \n",
      "8  user_00_0008 2025-10-15 14:48:00  2025-10-15   Wednesday    Control   \n",
      "9  user_00_0009 2025-10-15 21:56:00  2025-10-15   Wednesday    Control   \n",
      "\n",
      "   converted  revenue   device traffic_source  new_customer  page_views  \\\n",
      "0          0      0.0  Desktop    Paid Search          True           4   \n",
      "1          0      0.0   Mobile        Organic          True           3   \n",
      "2          0      0.0  Desktop          Email          True           4   \n",
      "3          0      0.0  Desktop        Organic          True           3   \n",
      "4          0      0.0  Desktop        Organic         False           7   \n",
      "5          0      0.0  Desktop         Direct          True           4   \n",
      "6          0      0.0   Mobile          Email          True           5   \n",
      "7          0      0.0  Desktop         Social         False           6   \n",
      "8          0      0.0  Desktop          Email          True           4   \n",
      "9          0      0.0  Desktop        Organic          True           4   \n",
      "\n",
      "   time_on_site  \n",
      "0    106.312084  \n",
      "1     88.145828  \n",
      "2    107.550872  \n",
      "3    160.824630  \n",
      "4    121.829526  \n",
      "5    288.696590  \n",
      "6    226.347589  \n",
      "7    229.207094  \n",
      "8     49.537904  \n",
      "9     65.951827  \n",
      "\n",
      "ðŸ“ˆ Quick Overview:\n",
      "Total Conversions: 1,373\n",
      "Total Revenue: $121,638.22\n",
      "Date Range: 2025-10-15 to 2025-10-28\n",
      "âœ… Generated 10,131 user records over 14 days\n",
      "ðŸ“Š Data shape: (10131, 12)\n",
      "ðŸ·ï¸ Groups: {np.str_('Treatment'): 5068, np.str_('Control'): 5063}\n",
      "\n",
      "ðŸ“‹ Sample Data:\n",
      "        user_id           timestamp        date day_of_week      group  \\\n",
      "0  user_00_0000 2025-10-15 22:42:00  2025-10-15   Wednesday    Control   \n",
      "1  user_00_0001 2025-10-15 19:20:00  2025-10-15   Wednesday  Treatment   \n",
      "2  user_00_0002 2025-10-15 21:46:00  2025-10-15   Wednesday    Control   \n",
      "3  user_00_0003 2025-10-15 12:01:00  2025-10-15   Wednesday  Treatment   \n",
      "4  user_00_0004 2025-10-15 21:05:00  2025-10-15   Wednesday  Treatment   \n",
      "5  user_00_0005 2025-10-15 19:59:00  2025-10-15   Wednesday    Control   \n",
      "6  user_00_0006 2025-10-15 15:34:00  2025-10-15   Wednesday    Control   \n",
      "7  user_00_0007 2025-10-15 18:34:00  2025-10-15   Wednesday  Treatment   \n",
      "8  user_00_0008 2025-10-15 14:48:00  2025-10-15   Wednesday    Control   \n",
      "9  user_00_0009 2025-10-15 21:56:00  2025-10-15   Wednesday    Control   \n",
      "\n",
      "   converted  revenue   device traffic_source  new_customer  page_views  \\\n",
      "0          0      0.0  Desktop    Paid Search          True           4   \n",
      "1          0      0.0   Mobile        Organic          True           3   \n",
      "2          0      0.0  Desktop          Email          True           4   \n",
      "3          0      0.0  Desktop        Organic          True           3   \n",
      "4          0      0.0  Desktop        Organic         False           7   \n",
      "5          0      0.0  Desktop         Direct          True           4   \n",
      "6          0      0.0   Mobile          Email          True           5   \n",
      "7          0      0.0  Desktop         Social         False           6   \n",
      "8          0      0.0  Desktop          Email          True           4   \n",
      "9          0      0.0  Desktop        Organic          True           4   \n",
      "\n",
      "   time_on_site  \n",
      "0    106.312084  \n",
      "1     88.145828  \n",
      "2    107.550872  \n",
      "3    160.824630  \n",
      "4    121.829526  \n",
      "5    288.696590  \n",
      "6    226.347589  \n",
      "7    229.207094  \n",
      "8     49.537904  \n",
      "9     65.951827  \n",
      "\n",
      "ðŸ“ˆ Quick Overview:\n",
      "Total Conversions: 1,373\n",
      "Total Revenue: $121,638.22\n",
      "Date Range: 2025-10-15 to 2025-10-28\n"
     ]
    }
   ],
   "source": [
    "# Generate realistic AB test data\n",
    "def generate_realistic_ab_test_data():\n",
    "    \"\"\"\n",
    "    Generate realistic AB test data for an e-commerce checkout button test\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    \n",
    "    # Test parameters\n",
    "    test_duration_days = 14\n",
    "    daily_visitors = 800\n",
    "    total_visitors = test_duration_days * daily_visitors\n",
    "    \n",
    "    # Control group parameters (current design)\n",
    "    control_conversion_rate = 0.12  # 12% baseline conversion\n",
    "    control_avg_order_value = 85\n",
    "    \n",
    "    # Treatment group parameters (new design) - slightly better\n",
    "    treatment_conversion_rate = 0.145  # 14.5% conversion (+20.8% relative improvement)\n",
    "    treatment_avg_order_value = 88  # Slightly higher AOV\n",
    "    \n",
    "    # Generate user data\n",
    "    user_data = []\n",
    "    \n",
    "    start_date = datetime(2025, 10, 15)\n",
    "    \n",
    "    for day in range(test_duration_days):\n",
    "        current_date = start_date + timedelta(days=day)\n",
    "        \n",
    "        # Simulate daily traffic variation (weekends have different patterns)\n",
    "        if current_date.weekday() >= 5:  # Weekend\n",
    "            daily_traffic = int(daily_visitors * 0.8)  # 20% less traffic on weekends\n",
    "        else:\n",
    "            daily_traffic = daily_visitors\n",
    "            \n",
    "        # Add some randomness to daily traffic\n",
    "        daily_traffic = int(daily_traffic * np.random.uniform(0.85, 1.15))\n",
    "        \n",
    "        for visitor_id in range(daily_traffic):\n",
    "            # Random assignment to groups (50/50 split)\n",
    "            group = np.random.choice(['Control', 'Treatment'])\n",
    "            \n",
    "            # Generate timestamp within the day\n",
    "            hour = np.random.randint(8, 23)  # Business hours 8 AM - 11 PM\n",
    "            minute = np.random.randint(0, 60)\n",
    "            timestamp = current_date.replace(hour=hour, minute=minute)\n",
    "            \n",
    "            # Determine conversion based on group\n",
    "            if group == 'Control':\n",
    "                converted = np.random.binomial(1, control_conversion_rate)\n",
    "                base_order_value = control_avg_order_value\n",
    "            else:\n",
    "                converted = np.random.binomial(1, treatment_conversion_rate)\n",
    "                base_order_value = treatment_avg_order_value\n",
    "            \n",
    "            # Generate revenue if converted\n",
    "            if converted:\n",
    "                # Revenue follows a gamma distribution (realistic for e-commerce)\n",
    "                revenue = np.random.gamma(2, base_order_value/2)\n",
    "                revenue = max(10, revenue)  # Minimum order value\n",
    "            else:\n",
    "                revenue = 0\n",
    "            \n",
    "            # Generate user demographics and behavior\n",
    "            user_data.append({\n",
    "                'user_id': f\"user_{day:02d}_{visitor_id:04d}\",\n",
    "                'timestamp': timestamp,\n",
    "                'date': current_date.date(),\n",
    "                'day_of_week': current_date.strftime('%A'),\n",
    "                'group': group,\n",
    "                'converted': converted,\n",
    "                'revenue': revenue,\n",
    "                'device': np.random.choice(['Desktop', 'Mobile', 'Tablet'], p=[0.6, 0.35, 0.05]),\n",
    "                'traffic_source': np.random.choice(['Organic', 'Paid Search', 'Social', 'Direct', 'Email'], \n",
    "                                                 p=[0.35, 0.25, 0.15, 0.15, 0.10]),\n",
    "                'new_customer': np.random.choice([True, False], p=[0.7, 0.3]),\n",
    "                'page_views': np.random.poisson(4) + 1,  # Number of pages viewed\n",
    "                'time_on_site': np.random.gamma(2, 60)  # Time in seconds\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(user_data)\n",
    "\n",
    "# Generate the data\n",
    "print(\"ðŸŽ² Generating realistic AB test data...\")\n",
    "df = generate_realistic_ab_test_data()\n",
    "\n",
    "print(f\"âœ… Generated {len(df):,} user records over {df['date'].nunique()} days\")\n",
    "print(f\"ðŸ“Š Data shape: {df.shape}\")\n",
    "print(f\"ðŸ·ï¸ Groups: {df['group'].value_counts().to_dict()}\")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nðŸ“‹ Sample Data:\")\n",
    "print(df.head(10))\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Quick Overview:\")\n",
    "print(f\"Total Conversions: {df['converted'].sum():,}\")\n",
    "print(f\"Total Revenue: ${df['revenue'].sum():,.2f}\")\n",
    "print(f\"Date Range: {df['date'].min()} to {df['date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2deda61",
   "metadata": {},
   "source": [
    "## ðŸ§¹ Step 3: Data Preprocessing and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62e69abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” DATA EXPLORATION AND PREPROCESSING\n",
      "==================================================\n",
      "\n",
      "1. DATASET OVERVIEW\n",
      "------------------------------\n",
      "ðŸ“Š Dataset shape: (10131, 12)\n",
      "ðŸ“… Date range: 2025-10-15 to 2025-10-28\n",
      "ðŸŽ¯ Total users: 10,131\n",
      "ðŸ’° Total revenue: $121,638.22\n",
      "\n",
      "2. DATA QUALITY CHECK\n",
      "------------------------------\n",
      "Data types:\n",
      "user_id                   object\n",
      "timestamp         datetime64[ns]\n",
      "date                      object\n",
      "day_of_week               object\n",
      "group                     object\n",
      "converted                  int64\n",
      "revenue                  float64\n",
      "device                    object\n",
      "traffic_source            object\n",
      "new_customer                bool\n",
      "page_views                 int64\n",
      "time_on_site             float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "user_id           0\n",
      "timestamp         0\n",
      "date              0\n",
      "day_of_week       0\n",
      "group             0\n",
      "converted         0\n",
      "revenue           0\n",
      "device            0\n",
      "traffic_source    0\n",
      "new_customer      0\n",
      "page_views        0\n",
      "time_on_site      0\n",
      "dtype: int64\n",
      "\n",
      "3. GROUP DISTRIBUTION\n",
      "------------------------------\n",
      "           Users  Conversions  Conv_Rate  Total_Revenue  Avg_Revenue_Per_User\n",
      "group                                                                        \n",
      "Control     5063          596     0.1177     52878.4703               10.4441\n",
      "Treatment   5068          777     0.1533     68759.7476               13.5674\n",
      "\n",
      "4. DAILY TRENDS\n",
      "------------------------------\n",
      "Sample daily data:\n",
      "                      Users  Conversions  Conv_Rate\n",
      "date       group                                   \n",
      "2025-10-15 Control      392           38     0.0969\n",
      "           Treatment    377           63     0.1671\n",
      "2025-10-16 Control      363           54     0.1488\n",
      "           Treatment    350           50     0.1429\n",
      "2025-10-17 Control      378           48     0.1270\n",
      "           Treatment    359           43     0.1198\n",
      "2025-10-18 Control      349           44     0.1261\n",
      "           Treatment    348           60     0.1724\n",
      "\n",
      "5. SEGMENT ANALYSIS\n",
      "------------------------------\n",
      "By Device:\n",
      "group    Control  Treatment\n",
      "device                     \n",
      "Desktop   0.1168     0.1578\n",
      "Mobile    0.1215     0.1465\n",
      "Tablet    0.1027     0.1441\n",
      "\n",
      "By Traffic Source:\n",
      "group           Control  Treatment\n",
      "traffic_source                    \n",
      "Direct           0.1159     0.1791\n",
      "Email            0.1186     0.1434\n",
      "Organic          0.1156     0.1582\n",
      "Paid Search      0.1179     0.1454\n",
      "Social           0.1234     0.1359\n",
      "\n",
      "6. TEMPORAL PATTERNS\n",
      "------------------------------\n",
      "group    Control  Treatment\n",
      "Weekday   0.1196     0.1528\n",
      "Weekend   0.1120     0.1549\n",
      "\n",
      "âœ… Data exploration complete!\n",
      "ðŸ“Š Data is clean and ready for statistical analysis\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing and exploration\n",
    "print(\"ðŸ” DATA EXPLORATION AND PREPROCESSING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Basic data info\n",
    "print(\"\\n1. DATASET OVERVIEW\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"ðŸ“Š Dataset shape: {df.shape}\")\n",
    "print(f\"ðŸ“… Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"ðŸŽ¯ Total users: {len(df):,}\")\n",
    "print(f\"ðŸ’° Total revenue: ${df['revenue'].sum():,.2f}\")\n",
    "\n",
    "# 2. Data types and missing values\n",
    "print(f\"\\n2. DATA QUALITY CHECK\")\n",
    "print(\"-\" * 30)\n",
    "print(\"Data types:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 3. Group balance\n",
    "print(f\"\\n3. GROUP DISTRIBUTION\")\n",
    "print(\"-\" * 30)\n",
    "group_stats = df.groupby('group').agg({\n",
    "    'user_id': 'count',\n",
    "    'converted': ['sum', 'mean'],\n",
    "    'revenue': ['sum', 'mean']\n",
    "}).round(4)\n",
    "\n",
    "group_stats.columns = ['Users', 'Conversions', 'Conv_Rate', 'Total_Revenue', 'Avg_Revenue_Per_User']\n",
    "print(group_stats)\n",
    "\n",
    "# 4. Daily trends\n",
    "print(f\"\\n4. DAILY TRENDS\")\n",
    "print(\"-\" * 30)\n",
    "daily_stats = df.groupby(['date', 'group']).agg({\n",
    "    'user_id': 'count',\n",
    "    'converted': ['sum', 'mean']\n",
    "}).round(4)\n",
    "\n",
    "daily_stats.columns = ['Users', 'Conversions', 'Conv_Rate']\n",
    "print(\"Sample daily data:\")\n",
    "print(daily_stats.head(8))\n",
    "\n",
    "# 5. Device and traffic source breakdown\n",
    "print(f\"\\n5. SEGMENT ANALYSIS\")\n",
    "print(\"-\" * 30)\n",
    "print(\"By Device:\")\n",
    "device_analysis = df.groupby(['device', 'group'])['converted'].mean().unstack().round(4)\n",
    "print(device_analysis)\n",
    "\n",
    "print(\"\\nBy Traffic Source:\")\n",
    "traffic_analysis = df.groupby(['traffic_source', 'group'])['converted'].mean().unstack().round(4)\n",
    "print(traffic_analysis)\n",
    "\n",
    "# 6. Weekend vs Weekday patterns\n",
    "print(f\"\\n6. TEMPORAL PATTERNS\")\n",
    "print(\"-\" * 30)\n",
    "df['is_weekend'] = df['day_of_week'].isin(['Saturday', 'Sunday'])\n",
    "temporal_analysis = df.groupby(['is_weekend', 'group'])['converted'].mean().unstack().round(4)\n",
    "temporal_analysis.index = ['Weekday', 'Weekend']\n",
    "print(temporal_analysis)\n",
    "\n",
    "print(\"\\nâœ… Data exploration complete!\")\n",
    "print(\"ðŸ“Š Data is clean and ready for statistical analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb685071",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Step 4: Statistical Analysis (Your Proven Methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cb47220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª COMPREHENSIVE AB TEST STATISTICAL ANALYSIS\n",
      "============================================================\n",
      "\n",
      "1. BASIC STATISTICS\n",
      "------------------------------\n",
      "Control: 596/5063 = 0.1177 (11.77%)\n",
      "Treatment: 777/5068 = 0.1533 (15.33%)\n",
      "Absolute difference: 0.0356 (3.56 percentage points)\n",
      "Relative change: 30.2%\n",
      "\n",
      "2. STATISTICAL SIGNIFICANCE\n",
      "------------------------------\n",
      "Z-statistic: -5.2341\n",
      "P-value: 0.000000\n",
      "Significant at Î±=0.05: YES\n",
      "\n",
      "3. CONFIDENCE INTERVALS\n",
      "------------------------------\n",
      "Control 95% CI: [0.1091, 0.1269] = [10.91%, 12.69%]\n",
      "Treatment 95% CI: [0.1437, 0.1635] = [14.37%, 16.35%]\n",
      "Difference 95% CI: [0.0223, 0.0489] = [2.23pp, 4.89pp]\n",
      "\n",
      "4. EFFECT SIZE\n",
      "------------------------------\n",
      "Cohen's h: 0.1042\n",
      "Effect magnitude: Small\n",
      "\n",
      "5. POWER ANALYSIS\n",
      "------------------------------\n",
      "Current statistical power: 0.999 (99.9%)\n",
      "\n",
      "6. BAYESIAN ANALYSIS\n",
      "------------------------------\n",
      "Probability treatment is better than control: 1.0000 (100.0%)\n",
      "Probability treatment is >10% better: 0.9996 (100.0%)\n",
      "\n",
      "7. SAMPLE SIZE PLANNING FOR FUTURE TESTS\n",
      "------------------------------\n",
      "âœ… Statistical analysis complete!\n",
      "ðŸ“Š Key Result: Treatment shows 30.2% improvement\n",
      "ðŸŽ¯ Significance: SIGNIFICANT (p=0.0000)\n"
     ]
    }
   ],
   "source": [
    "# Statistical Analysis - Using your proven methods\n",
    "from statsmodels.stats.proportion import proportions_ztest, proportion_confint\n",
    "\n",
    "# Extract the key numbers for analysis\n",
    "control_data = df[df['group'] == 'Control']\n",
    "treatment_data = df[df['group'] == 'Treatment']\n",
    "\n",
    "control_users = len(control_data)\n",
    "control_conversions = control_data['converted'].sum()\n",
    "treatment_users = len(treatment_data)\n",
    "treatment_conversions = treatment_data['converted'].sum()\n",
    "\n",
    "print(\"ðŸ§ª COMPREHENSIVE AB TEST STATISTICAL ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. BASIC STATISTICS\n",
    "print(\"\\n1. BASIC STATISTICS\")\n",
    "print(\"-\" * 30)\n",
    "control_rate = control_conversions / control_users\n",
    "treatment_rate = treatment_conversions / treatment_users\n",
    "difference = treatment_rate - control_rate\n",
    "relative_change = (difference / control_rate) * 100\n",
    "\n",
    "print(f\"Control: {control_conversions}/{control_users} = {control_rate:.4f} ({control_rate*100:.2f}%)\")\n",
    "print(f\"Treatment: {treatment_conversions}/{treatment_users} = {treatment_rate:.4f} ({treatment_rate*100:.2f}%)\")\n",
    "print(f\"Absolute difference: {difference:.4f} ({difference*100:.2f} percentage points)\")\n",
    "print(f\"Relative change: {relative_change:.1f}%\")\n",
    "\n",
    "# 2. STATISTICAL SIGNIFICANCE TESTING\n",
    "print(\"\\n2. STATISTICAL SIGNIFICANCE\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Two-proportion z-test\n",
    "successes = [control_conversions, treatment_conversions]\n",
    "totals = [control_users, treatment_users]\n",
    "z_stat, p_value = proportions_ztest(successes, totals)\n",
    "\n",
    "print(f\"Z-statistic: {z_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.6f}\")\n",
    "print(f\"Significant at Î±=0.05: {'YES' if p_value < 0.05 else 'NO'}\")\n",
    "\n",
    "# 3. CONFIDENCE INTERVALS\n",
    "print(\"\\n3. CONFIDENCE INTERVALS\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Individual CIs\n",
    "control_ci = proportion_confint(control_conversions, control_users, alpha=0.05, method='wilson')\n",
    "treatment_ci = proportion_confint(treatment_conversions, treatment_users, alpha=0.05, method='wilson')\n",
    "\n",
    "print(f\"Control 95% CI: [{control_ci[0]:.4f}, {control_ci[1]:.4f}] = [{control_ci[0]*100:.2f}%, {control_ci[1]*100:.2f}%]\")\n",
    "print(f\"Treatment 95% CI: [{treatment_ci[0]:.4f}, {treatment_ci[1]:.4f}] = [{treatment_ci[0]*100:.2f}%, {treatment_ci[1]*100:.2f}%]\")\n",
    "\n",
    "# Difference CI (approximation)\n",
    "se_diff = np.sqrt(control_rate*(1-control_rate)/control_users + treatment_rate*(1-treatment_rate)/treatment_users)\n",
    "diff_ci_lower = difference - 1.96 * se_diff\n",
    "diff_ci_upper = difference + 1.96 * se_diff\n",
    "print(f\"Difference 95% CI: [{diff_ci_lower:.4f}, {diff_ci_upper:.4f}] = [{diff_ci_lower*100:.2f}pp, {diff_ci_upper*100:.2f}pp]\")\n",
    "\n",
    "# 4. EFFECT SIZE (Cohen's h for proportions)\n",
    "print(\"\\n4. EFFECT SIZE\")\n",
    "print(\"-\" * 30)\n",
    "cohens_h = 2 * (np.arcsin(np.sqrt(treatment_rate)) - np.arcsin(np.sqrt(control_rate)))\n",
    "print(f\"Cohen's h: {cohens_h:.4f}\")\n",
    "if abs(cohens_h) < 0.2:\n",
    "    effect_magnitude = \"Small\"\n",
    "elif abs(cohens_h) < 0.5:\n",
    "    effect_magnitude = \"Medium\"\n",
    "else:\n",
    "    effect_magnitude = \"Large\"\n",
    "print(f\"Effect magnitude: {effect_magnitude}\")\n",
    "\n",
    "# 5. POWER ANALYSIS\n",
    "print(\"\\n5. POWER ANALYSIS\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "def calculate_power(n1, n2, p1, p2, alpha=0.05):\n",
    "    \"\"\"Calculate statistical power for two-proportion test\"\"\"\n",
    "    pooled_p = (n1*p1 + n2*p2) / (n1 + n2)\n",
    "    se_null = np.sqrt(pooled_p * (1 - pooled_p) * (1/n1 + 1/n2))\n",
    "    se_alt = np.sqrt(p1*(1-p1)/n1 + p2*(1-p2)/n2)\n",
    "    \n",
    "    z_alpha = stats.norm.ppf(1 - alpha/2)\n",
    "    z_beta = (abs(p1 - p2) - z_alpha * se_null) / se_alt\n",
    "    power = stats.norm.cdf(z_beta)\n",
    "    \n",
    "    return max(0, min(1, power))\n",
    "\n",
    "current_power = calculate_power(control_users, treatment_users, control_rate, treatment_rate)\n",
    "print(f\"Current statistical power: {current_power:.3f} ({current_power*100:.1f}%)\")\n",
    "\n",
    "# 6. BAYESIAN ANALYSIS\n",
    "print(\"\\n6. BAYESIAN ANALYSIS\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Beta-binomial model with uniform priors\n",
    "alpha_control = 1 + control_conversions\n",
    "beta_control = 1 + control_users - control_conversions\n",
    "alpha_treatment = 1 + treatment_conversions\n",
    "beta_treatment = 1 + treatment_users - treatment_conversions\n",
    "\n",
    "# Probability that treatment is better than control\n",
    "n_samples = 100000\n",
    "control_samples = np.random.beta(alpha_control, beta_control, n_samples)\n",
    "treatment_samples = np.random.beta(alpha_treatment, beta_treatment, n_samples)\n",
    "\n",
    "prob_treatment_better = np.mean(treatment_samples > control_samples)\n",
    "prob_treatment_much_better = np.mean(treatment_samples > 1.1 * control_samples)  # >10% better\n",
    "\n",
    "print(f\"Probability treatment is better than control: {prob_treatment_better:.4f} ({prob_treatment_better*100:.1f}%)\")\n",
    "print(f\"Probability treatment is >10% better: {prob_treatment_much_better:.4f} ({prob_treatment_much_better*100:.1f}%)\")\n",
    "\n",
    "# 7. SAMPLE SIZE PLANNING\n",
    "print(\"\\n7. SAMPLE SIZE PLANNING FOR FUTURE TESTS\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "def sample_size_calculator(p1, p2, alpha=0.05, power=0.8):\n",
    "    \"\"\"Calculate required sample size per group\"\"\"\n",
    "    p_pooled = (p1 + p2) / 2\n",
    "    effect_size = abs(p1 - p2)\n",
    "    \n",
    "    z_alpha = stats.norm.ppf(1 - alpha/2)\n",
    "    z_beta = stats.norm.ppf(power)\n",
    "    \n",
    "    n = (z_alpha + z_beta)**2 * p_pooled * (1 - p_pooled) / (effect_size**2)\n",
    "    return math.ceil(n)\n",
    "\n",
    "# Store results for Power BI export\n",
    "analysis_results = {\n",
    "    'control_users': control_users,\n",
    "    'control_conversions': control_conversions,\n",
    "    'treatment_users': treatment_users, \n",
    "    'treatment_conversions': treatment_conversions,\n",
    "    'control_rate': control_rate,\n",
    "    'treatment_rate': treatment_rate,\n",
    "    'difference': difference,\n",
    "    'relative_change': relative_change,\n",
    "    'z_stat': z_stat,\n",
    "    'p_value': p_value,\n",
    "    'cohens_h': cohens_h,\n",
    "    'current_power': current_power,\n",
    "    'prob_treatment_better': prob_treatment_better,\n",
    "    'control_ci': control_ci,\n",
    "    'treatment_ci': treatment_ci\n",
    "}\n",
    "\n",
    "print(\"âœ… Statistical analysis complete!\")\n",
    "print(f\"ðŸ“Š Key Result: Treatment shows {relative_change:.1f}% {'improvement' if relative_change > 0 else 'decline'}\")\n",
    "print(f\"ðŸŽ¯ Significance: {'SIGNIFICANT' if p_value < 0.05 else 'NOT SIGNIFICANT'} (p={p_value:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f3a710",
   "metadata": {},
   "source": [
    "## ðŸ“Š Step 5: Export Data for Power BI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d94739d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š CREATING POWER BI DATASETS\n",
      "========================================\n",
      "âœ… Power BI datasets created successfully!\n",
      "\n",
      "ðŸ“‚ Files created in 'powerbi_data' folder:\n",
      "  1. ab_test_summary.csv - Key metrics and statistical results\n",
      "  2. daily_performance.csv - Daily trends and performance\n",
      "  3. confidence_intervals.csv - Statistical confidence data\n",
      "  4. segment_analysis.csv - Device and traffic source breakdown\n",
      "  5. raw_user_sample.csv - Sample raw data for drill-down\n",
      "\n",
      "ðŸ“Š Summary Dataset Preview:\n",
      "                      Metric     Value          Category\n",
      "0              Control Users      5063       Sample Size\n",
      "1            Treatment Users      5068       Sample Size\n",
      "2        Control Conversions       596       Conversions\n",
      "3      Treatment Conversions       777       Conversions\n",
      "4    Control Conversion Rate    0.1177              Rate\n",
      "5  Treatment Conversion Rate    0.1533              Rate\n",
      "6        Absolute Difference    0.0356        Difference\n",
      "7     Relative Improvement %     30.24       Performance\n",
      "8                Z Statistic   -5.2341  Statistical Test\n",
      "9                    P Value  0.000000  Statistical Test\n",
      "\n",
      "ðŸ“ˆ Daily Performance Sample:\n",
      "         Date      Group  Users  Conversions  Conversion_Rate      Revenue  \\\n",
      "0  2025-10-15    Control    392           38         0.096939  3496.267344   \n",
      "1  2025-10-15  Treatment    377           63         0.167109  6284.053890   \n",
      "2  2025-10-16    Control    363           54         0.148760  5183.185298   \n",
      "3  2025-10-16  Treatment    350           50         0.142857  4550.567457   \n",
      "4  2025-10-17    Control    378           48         0.126984  4059.221082   \n",
      "5  2025-10-17  Treatment    359           43         0.119777  4439.343386   \n",
      "\n",
      "   Day_Number    Weekday  \n",
      "0           1  Wednesday  \n",
      "1           1  Wednesday  \n",
      "2           2   Thursday  \n",
      "3           2   Thursday  \n",
      "4           3     Friday  \n",
      "5           3     Friday  \n"
     ]
    }
   ],
   "source": [
    "# Create Power BI datasets\n",
    "import os\n",
    "\n",
    "# Create output directory\n",
    "output_dir = 'powerbi_data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"ðŸ“Š CREATING POWER BI DATASETS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# 1. SUMMARY STATISTICS TABLE\n",
    "summary_stats = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Control Users',\n",
    "        'Treatment Users',\n",
    "        'Control Conversions', \n",
    "        'Treatment Conversions',\n",
    "        'Control Conversion Rate',\n",
    "        'Treatment Conversion Rate',\n",
    "        'Absolute Difference',\n",
    "        'Relative Improvement %',\n",
    "        'Z Statistic',\n",
    "        'P Value',\n",
    "        'Statistical Significant',\n",
    "        'Effect Size (Cohen h)',\n",
    "        'Statistical Power',\n",
    "        'Prob Treatment Better',\n",
    "        'Test Duration (Days)',\n",
    "        'Total Revenue Control',\n",
    "        'Total Revenue Treatment',\n",
    "        'Revenue Per User Control',\n",
    "        'Revenue Per User Treatment'\n",
    "    ],\n",
    "    'Value': [\n",
    "        control_users,\n",
    "        treatment_users,\n",
    "        control_conversions,\n",
    "        treatment_conversions,\n",
    "        f\"{control_rate:.4f}\",\n",
    "        f\"{treatment_rate:.4f}\",\n",
    "        f\"{difference:.4f}\", \n",
    "        f\"{relative_change:.2f}\",\n",
    "        f\"{z_stat:.4f}\",\n",
    "        f\"{p_value:.6f}\",\n",
    "        'Yes' if p_value < 0.05 else 'No',\n",
    "        f\"{cohens_h:.4f}\",\n",
    "        f\"{current_power:.3f}\",\n",
    "        f\"{prob_treatment_better:.3f}\",\n",
    "        df['date'].nunique(),\n",
    "        f\"{control_data['revenue'].sum():.2f}\",\n",
    "        f\"{treatment_data['revenue'].sum():.2f}\",\n",
    "        f\"{control_data['revenue'].sum()/control_users:.2f}\",\n",
    "        f\"{treatment_data['revenue'].sum()/treatment_users:.2f}\"\n",
    "    ],\n",
    "    'Category': [\n",
    "        'Sample Size', 'Sample Size', 'Conversions', 'Conversions',\n",
    "        'Rate', 'Rate', 'Difference', 'Performance',\n",
    "        'Statistical Test', 'Statistical Test', 'Result', 'Effect',\n",
    "        'Power', 'Bayesian', 'Duration',\n",
    "        'Revenue', 'Revenue', 'Revenue', 'Revenue'\n",
    "    ]\n",
    "})\n",
    "\n",
    "# 2. DAILY PERFORMANCE DATA\n",
    "daily_data = df.groupby(['date', 'group']).agg({\n",
    "    'user_id': 'count',\n",
    "    'converted': ['sum', 'mean'],\n",
    "    'revenue': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "daily_data.columns = ['Date', 'Group', 'Users', 'Conversions', 'Conversion_Rate', 'Revenue']\n",
    "daily_data['Day_Number'] = daily_data['Date'].rank(method='dense').astype(int)\n",
    "daily_data['Weekday'] = pd.to_datetime(daily_data['Date']).dt.day_name()\n",
    "\n",
    "# 3. CONFIDENCE INTERVALS DATA\n",
    "ci_data = pd.DataFrame({\n",
    "    'Group': ['Control', 'Treatment'],\n",
    "    'Conversion_Rate': [control_rate, treatment_rate],\n",
    "    'Users': [control_users, treatment_users],\n",
    "    'Conversions': [control_conversions, treatment_conversions],\n",
    "    'CI_Lower': [control_ci[0], treatment_ci[0]],\n",
    "    'CI_Upper': [control_ci[1], treatment_ci[1]],\n",
    "    'Margin_of_Error': [control_ci[1] - control_rate, treatment_ci[1] - treatment_rate]\n",
    "})\n",
    "\n",
    "# 4. SEGMENT ANALYSIS DATA\n",
    "segment_data = []\n",
    "\n",
    "# Device analysis\n",
    "for device in df['device'].unique():\n",
    "    for group in ['Control', 'Treatment']:\n",
    "        subset = df[(df['device'] == device) & (df['group'] == group)]\n",
    "        if len(subset) > 0:\n",
    "            segment_data.append({\n",
    "                'Segment_Type': 'Device',\n",
    "                'Segment_Value': device,\n",
    "                'Group': group,\n",
    "                'Users': len(subset),\n",
    "                'Conversions': subset['converted'].sum(),\n",
    "                'Conversion_Rate': subset['converted'].mean(),\n",
    "                'Revenue': subset['revenue'].sum()\n",
    "            })\n",
    "\n",
    "# Traffic source analysis  \n",
    "for source in df['traffic_source'].unique():\n",
    "    for group in ['Control', 'Treatment']:\n",
    "        subset = df[(df['traffic_source'] == source) & (df['group'] == group)]\n",
    "        if len(subset) > 0:\n",
    "            segment_data.append({\n",
    "                'Segment_Type': 'Traffic_Source',\n",
    "                'Segment_Value': source,\n",
    "                'Group': group,\n",
    "                'Users': len(subset),\n",
    "                'Conversions': subset['converted'].sum(),\n",
    "                'Conversion_Rate': subset['converted'].mean(),\n",
    "                'Revenue': subset['revenue'].sum()\n",
    "            })\n",
    "\n",
    "segment_df = pd.DataFrame(segment_data)\n",
    "\n",
    "# 5. RAW USER DATA (SAMPLE FOR POWER BI)\n",
    "# Include a sample of raw data for drill-down analysis\n",
    "raw_sample = df.sample(n=min(5000, len(df)), random_state=42).copy()\n",
    "raw_sample['Revenue_Per_User'] = raw_sample['revenue']\n",
    "raw_sample['Converted_Text'] = raw_sample['converted'].map({0: 'No', 1: 'Yes'})\n",
    "\n",
    "# Export all datasets\n",
    "summary_stats.to_csv(f'{output_dir}/ab_test_summary.csv', index=False)\n",
    "daily_data.to_csv(f'{output_dir}/daily_performance.csv', index=False)\n",
    "ci_data.to_csv(f'{output_dir}/confidence_intervals.csv', index=False) \n",
    "segment_df.to_csv(f'{output_dir}/segment_analysis.csv', index=False)\n",
    "raw_sample.to_csv(f'{output_dir}/raw_user_sample.csv', index=False)\n",
    "\n",
    "print(\"âœ… Power BI datasets created successfully!\")\n",
    "print(f\"\\nðŸ“‚ Files created in '{output_dir}' folder:\")\n",
    "print(\"  1. ab_test_summary.csv - Key metrics and statistical results\")\n",
    "print(\"  2. daily_performance.csv - Daily trends and performance\")\n",
    "print(\"  3. confidence_intervals.csv - Statistical confidence data\")\n",
    "print(\"  4. segment_analysis.csv - Device and traffic source breakdown\")\n",
    "print(\"  5. raw_user_sample.csv - Sample raw data for drill-down\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Summary Dataset Preview:\")\n",
    "print(summary_stats.head(10))\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Daily Performance Sample:\")\n",
    "print(daily_data.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9afbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Š AB Test Template: From Raw Data to Power BI Dashboard\n",
    "\n",
    "This notebook demonstrates the complete workflow from raw data collection to statistical analysis and Power BI visualization.\n",
    "\n",
    "## ðŸŽ¯ What This Template Covers\n",
    "\n",
    "1. **Raw Data Generation** - Realistic AB test data simulation\n",
    "2. **Data Preprocessing** - Cleaning and preparation\n",
    "3. **Statistical Analysis** - Comprehensive AB test analysis  \n",
    "4. **Power BI Export** - Structured data for dashboards\n",
    "5. **Visualization Guidelines** - Power BI dashboard templates\n",
    "\n",
    "## ðŸ“‹ Sample Scenario\n",
    "\n",
    "**Company:** E-commerce website  \n",
    "**Test:** New checkout button design vs. current design  \n",
    "**Metric:** Conversion rate (purchases/visitors)  \n",
    "**Duration:** 14 days  \n",
    "**Traffic Split:** 50/50  \n",
    "\n",
    "Let's build this step by step!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
