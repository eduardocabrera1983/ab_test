{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1ca031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d150f7",
   "metadata": {},
   "source": [
    "SAMPLE SIZE CALULATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc38f34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required sample size per group: 146\n"
     ]
    }
   ],
   "source": [
    "# Current rates (example)\n",
    "p1 = 53/640   # 0.082812 (8.82%)\n",
    "p2 = 45/1530   # 0.029412 (2.94%)\n",
    "\n",
    "# For statistical power calculation, you need:\n",
    "# 1. Baseline conversion rate (estimate from control)\n",
    "# 2. Minimum effect size you want to detect\n",
    "# 3. Statistical power (usually 80%)\n",
    "# 4. Significance level (usually 5%)\n",
    "\n",
    "def sample_size_calculator(p1, p2, alpha=0.05, power=0.8):\n",
    "    \"\"\"Calculate required sample size per group\"\"\"\n",
    "    p_pooled = (p1 + p2) / 2\n",
    "    effect_size = abs(p1 - p2)\n",
    "    \n",
    "    z_alpha = stats.norm.ppf(1 - alpha/2)  # 1.96 for 95% confidence\n",
    "    z_beta = stats.norm.ppf(power)         # 0.84 for 80% power\n",
    "    \n",
    "    n = (z_alpha + z_beta)**2 * p_pooled * (1 - p_pooled) / (effect_size**2)\n",
    "    return math.ceil(n)\n",
    "\n",
    "# example\n",
    "required_n = sample_size_calculator(0.082812, 0.029412)\n",
    "print(f\"Required sample size per group: {required_n:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db5b7d0",
   "metadata": {},
   "source": [
    "DAYS NEEDED TO ACHIEVE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e5b43c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 2% â†’ 3% detection: 1,914 users per group\n",
      "Current daily traffic: ~136 users\n",
      "Days needed: 28\n"
     ]
    }
   ],
   "source": [
    "# Let's say your true baseline is around 2% and you want to detect a 50% relative change\n",
    "baseline_rate = 0.02  # 2% baseline\n",
    "min_detectable_effect = 0.01  # 1% absolute change (50% relative)\n",
    "\n",
    "required_n = sample_size_calculator(baseline_rate, baseline_rate + min_detectable_effect)\n",
    "print(f\"For 2% â†’ 3% detection: {required_n:,} users per group\")\n",
    "\n",
    "# Your current traffic rate\n",
    "current_daily_users = (640 + 1530) / 16  # assuming 17 days based on dates\n",
    "print(f\"Current daily traffic: ~{current_daily_users:.0f} users\")\n",
    "print(f\"Days needed: {(required_n * 2) / current_daily_users:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a243bd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b26846a",
   "metadata": {},
   "source": [
    "STATISTICS ON CONTROL AND TEST GROUPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b139cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control group conversion rate: 0.077\n",
      "test group conversion rate: 0.028\n",
      "Z-statistic: 5.3074\n",
      "P-value: 0.000000111201\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "control_conversions = 53    # people who converted in control group\n",
    "control_total = 685       # total people in control group\n",
    "\n",
    "test_conversions = 46     # people who converted in test group  \n",
    "test_total = 1622         # total people in test\n",
    "\n",
    "# Two-proportion z-test\n",
    "successes = [control_conversions, test_conversions]  # [17, 7]\n",
    "totals = [control_total, test_total] # [685, 1622]\n",
    "\n",
    "z_stat, p_value = proportions_ztest(successes, totals)\n",
    "\n",
    "print(f\"Control group conversion rate: {control_conversions/control_total:.3f}\")\n",
    "print(f\"test group conversion rate: {test_conversions/test_total:.3f}\")\n",
    "print(f\"Z-statistic: {z_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.12f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1459b76",
   "metadata": {},
   "source": [
    "AB TEST STATISTICS ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe215157",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'Python 3.11.9' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import beta\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.proportion import proportions_ztest, proportion_confint\n",
    "from statsmodels.stats.power import ttest_power\n",
    "\n",
    "# Your current data\n",
    "control_users = 640\n",
    "control_conversions = 53  # unique users with shipments\n",
    "test_users = 1530\n",
    "test_conversions = 45\n",
    "\n",
    "# Also shipment rates for additional analysis\n",
    "control_shipments = 53\n",
    "test_shipments = 45\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPREHENSIVE A/B TEST ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. BASIC STATISTICS\n",
    "print(\"\\n1. BASIC STATISTICS\")\n",
    "print(\"-\" * 30)\n",
    "control_rate = control_conversions / control_users\n",
    "test_rate = test_conversions / test_users\n",
    "difference = test_rate - control_rate\n",
    "relative_change = (difference / control_rate) * 100\n",
    "\n",
    "print(f\"Control: {control_conversions}/{control_users} = {control_rate:.4f} ({control_rate*100:.2f}%)\")\n",
    "print(f\"Test: {test_conversions}/{test_users} = {test_rate:.4f} ({test_rate*100:.2f}%)\")\n",
    "print(f\"Absolute difference: {difference:.4f} ({difference*100:.2f} pp)\")\n",
    "print(f\"Relative change: {relative_change:.1f}%\")\n",
    "\n",
    "# 2. STATISTICAL SIGNIFICANCE TESTING\n",
    "print(\"\\n2. STATISTICAL SIGNIFICANCE\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Two-proportion z-test\n",
    "successes = [control_conversions, test_conversions]\n",
    "totals = [control_users, test_users]\n",
    "z_stat, p_value = proportions_ztest(successes, totals)\n",
    "\n",
    "print(f\"Z-statistic: {z_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.12f}\")\n",
    "print(f\"Significant at Î±=0.05: {'YES' if p_value < 0.05 else 'NO'}\")\n",
    "\n",
    "# 3. CONFIDENCE INTERVALS\n",
    "print(\"\\n3. CONFIDENCE INTERVALS\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Individual CIs\n",
    "control_ci = proportion_confint(control_conversions, control_users, alpha=0.05, method='wilson')\n",
    "test_ci = proportion_confint(test_conversions, test_users, alpha=0.05, method='wilson')\n",
    "\n",
    "print(f\"Control 95% CI: [{control_ci[0]:.4f}, {control_ci[1]:.4f}] = [{control_ci[0]*100:.2f}%, {control_ci[1]*100:.2f}%]\")\n",
    "print(f\"Test 95% CI: [{test_ci[0]:.4f}, {test_ci[1]:.4f}] = [{test_ci[0]*100:.2f}%, {test_ci[1]*100:.2f}%]\")\n",
    "\n",
    "# Difference CI (approximation)\n",
    "se_diff = np.sqrt(control_rate*(1-control_rate)/control_users + test_rate*(1-test_rate)/test_users)\n",
    "diff_ci_lower = difference - 1.96 * se_diff\n",
    "diff_ci_upper = difference + 1.96 * se_diff\n",
    "print(f\"Difference 95% CI: [{diff_ci_lower:.4f}, {diff_ci_upper:.4f}] = [{diff_ci_lower*100:.2f}pp, {diff_ci_upper*100:.2f}pp]\")\n",
    "\n",
    "# 4. EFFECT SIZE (Cohen's h for proportions)\n",
    "print(\"\\n4. EFFECT SIZE\")\n",
    "print(\"-\" * 30)\n",
    "cohens_h = 2 * (np.arcsin(np.sqrt(control_rate)) - np.arcsin(np.sqrt(test_rate)))\n",
    "print(f\"Cohen's h: {cohens_h:.4f}\")\n",
    "if abs(cohens_h) < 0.2:\n",
    "    effect_magnitude = \"Small\"\n",
    "elif abs(cohens_h) < 0.5:\n",
    "    effect_magnitude = \"Medium\"\n",
    "else:\n",
    "    effect_magnitude = \"Large\"\n",
    "print(f\"Effect magnitude: {effect_magnitude}\")\n",
    "\n",
    "# 5. POWER ANALYSIS FOR CURRENT TEST\n",
    "print(\"\\n5. CURRENT POWER ANALYSIS\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "def calculate_power(n1, n2, p1, p2, alpha=0.05):\n",
    "    \"\"\"Calculate statistical power for two-proportion test\"\"\"\n",
    "    pooled_p = (n1*p1 + n2*p2) / (n1 + n2)\n",
    "    se_null = np.sqrt(pooled_p * (1 - pooled_p) * (1/n1 + 1/n2))\n",
    "    se_alt = np.sqrt(p1*(1-p1)/n1 + p2*(1-p2)/n2)\n",
    "    \n",
    "    z_alpha = stats.norm.ppf(1 - alpha/2)\n",
    "    z_beta = (abs(p1 - p2) - z_alpha * se_null) / se_alt\n",
    "    power = stats.norm.cdf(z_beta)\n",
    "    \n",
    "    return max(0, min(1, power))\n",
    "\n",
    "current_power = calculate_power(control_users, test_users, control_rate, test_rate)\n",
    "print(f\"Current statistical power: {current_power:.3f} ({current_power*100:.1f}%)\")\n",
    "\n",
    "# 6. BAYESIAN ANALYSIS\n",
    "print(\"\\n6. BAYESIAN ANALYSIS\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Beta-binomial model with uniform priors\n",
    "alpha_control = 1 + control_conversions\n",
    "beta_control = 1 + control_users - control_conversions\n",
    "alpha_test = 1 + test_conversions\n",
    "beta_test = 1 + test_users - test_conversions\n",
    "\n",
    "# Probability that test is worse than control\n",
    "n_samples = 100000\n",
    "control_samples = np.random.beta(alpha_control, beta_control, n_samples)\n",
    "test_samples = np.random.beta(alpha_test, beta_test, n_samples)\n",
    "\n",
    "prob_test_worse = np.mean(test_samples < control_samples)\n",
    "prob_test_much_worse = np.mean(test_samples < 0.5 * control_samples)  # >50% worse\n",
    "\n",
    "print(f\"Probability test is worse than control: {prob_test_worse:.4f} ({prob_test_worse*100:.1f}%)\")\n",
    "print(f\"Probability test is >50% worse: {prob_test_much_worse:.4f} ({prob_test_much_worse*100:.1f}%)\")\n",
    "\n",
    "# 7. SAMPLE SIZE FOR FUTURE TESTS\n",
    "print(\"\\n7. SAMPLE SIZE PLANNING FOR FUTURE TESTS\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "def sample_size_calculator(p1, p2, alpha=0.05, power=0.8):\n",
    "    \"\"\"Calculate required sample size per group\"\"\"\n",
    "    p_pooled = (p1 + p2) / 2\n",
    "    effect_size = abs(p1 - p2)\n",
    "    \n",
    "    z_alpha = stats.norm.ppf(1 - alpha/2)\n",
    "    z_beta = stats.norm.ppf(power)\n",
    "    \n",
    "    n = (z_alpha + z_beta)**2 * p_pooled * (1 - p_pooled) / (effect_size**2)\n",
    "    return math.ceil(n)\n",
    "\n",
    "# Scenarios for future tests (assuming control rate is true baseline)\n",
    "baseline = control_rate\n",
    "scenarios = [\n",
    "    (\"Detect 10% relative change\", baseline * 1.1),\n",
    "    (\"Detect 20% relative change\", baseline * 1.2),\n",
    "    (\"Detect 50% relative change\", baseline * 1.5),\n",
    "    (\"Detect current difference\", test_rate)\n",
    "]\n",
    "\n",
    "for scenario_name, p2 in scenarios:\n",
    "    if p2 > 0:\n",
    "        n_needed = sample_size_calculator(baseline, p2)\n",
    "        days_needed = (n_needed * 2) / ((control_users + test_users) / 17)  # 17 day test\n",
    "        print(f\"{scenario_name}: {n_needed:,} users per group ({days_needed:.0f} days)\")\n",
    "\n",
    "# 8. EARLY STOPPING RECOMMENDATION\n",
    "print(\"\\n8. EARLY STOPPING ANALYSIS\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Check if we have sufficient evidence to stop\n",
    "min_sample_for_significance = 30  # Rule of thumb minimum\n",
    "total_conversions = control_conversions + test_conversions\n",
    "\n",
    "print(f\"Total conversions: {total_conversions}\")\n",
    "print(f\"Minimum for reliable test: {min_sample_for_significance}\")\n",
    "print(f\"Current power: {current_power*100:.1f}%\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "if total_conversions >= min_sample_for_significance and p_value < 0.05:\n",
    "    print(\"âœ… STOP RECOMMENDATION: Sufficient evidence of significant negative effect\")\n",
    "elif prob_test_worse > 0.95:\n",
    "    print(\"âœ… STOP RECOMMENDATION: Bayesian analysis shows >95% probability test is worse\")\n",
    "else:\n",
    "    print(\"âš ï¸ CONTINUE RECOMMENDATION: Insufficient evidence (but this shouldn't apply to your case)\")\n",
    "\n",
    "# 9. BUSINESS IMPACT ANALYSIS\n",
    "print(\"\\n9. BUSINESS IMPACT\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Lost conversions due to skewed allocation\n",
    "if test_users > control_users:  # More traffic went to worse variant\n",
    "    expected_conversions_if_equal = control_rate * test_users\n",
    "    actual_test_conversions = test_conversions\n",
    "    lost_conversions = expected_conversions_if_equal - actual_test_conversions\n",
    "    \n",
    "    print(f\"Expected conversions if test users got control rate: {expected_conversions_if_equal:.1f}\")\n",
    "    print(f\"Actual test conversions: {actual_test_conversions}\")\n",
    "    print(f\"Lost conversions due to poor allocation: {lost_conversions:.1f}\")\n",
    "    print(f\"Opportunity cost: {(lost_conversions/(control_conversions + test_conversions))*100:.1f}% of total conversions\")\n",
    "\n",
    "# 10. FINAL RECOMMENDATIONS\n",
    "print(\"\\n10. FINAL RECOMMENDATIONS\")\n",
    "print(\"-\" * 30)\n",
    "print(\"Based on the analysis:\")\n",
    "print()\n",
    "\n",
    "if prob_test_worse > 0.95 and p_value < 0.05:\n",
    "    print(\"ðŸš¨ IMMEDIATE ACTION REQUIRED:\")\n",
    "    print(\"   â€¢ STOP the test immediately\")\n",
    "    print(\"   â€¢ Route 100% traffic to control\")\n",
    "    print(\"   â€¢ Test variant is definitively worse\")\n",
    "    print()\n",
    "    print(\"ðŸ” ROOT CAUSE INVESTIGATION:\")\n",
    "    print(\"   â€¢ Test variant has fundamental issues\")\n",
    "    print(\"   â€¢ Investigate what changed in promoted button\")\n",
    "    print(\"   â€¢ Fix core functionality before testing variants\")\n",
    "    print()\n",
    "    print(\"ðŸ“Š FUTURE TESTING:\")\n",
    "    print(\"   â€¢ Fix traffic allocation (50/50 split)\")\n",
    "    print(\"   â€¢ Plan for larger samples for smaller effects\")\n",
    "    print(\"   â€¢ Consider staged rollouts for major changes\")\n",
    "else:\n",
    "    print(\"ðŸ“ˆ Continue testing with more data\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5466075",
   "metadata": {},
   "source": [
    "## POWER BI DATA EXPORT\n",
    "\n",
    "Export the analysis results to CSV files for Power BI dashboard creation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610aa462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Power BI Export Data\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Create output directory\n",
    "output_dir = 'powerbi_data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 1. Summary Statistics for Power BI\n",
    "summary_data = {\n",
    "    'Metric': [\n",
    "        'Control Users',\n",
    "        'Test Users', \n",
    "        'Control Conversions',\n",
    "        'Test Conversions',\n",
    "        'Control Rate',\n",
    "        'Test Rate',\n",
    "        'Absolute Difference',\n",
    "        'Relative Change %',\n",
    "        'Z Statistic',\n",
    "        'P Value',\n",
    "        'Statistical Significant',\n",
    "        'Effect Size (Cohen h)',\n",
    "        'Current Power',\n",
    "        'Prob Test Worse than Control'\n",
    "    ],\n",
    "    'Value': [\n",
    "        control_users,\n",
    "        test_users,\n",
    "        control_conversions, \n",
    "        test_conversions,\n",
    "        f\"{control_rate:.4f}\",\n",
    "        f\"{test_rate:.4f}\",\n",
    "        f\"{difference:.4f}\",\n",
    "        f\"{relative_change:.2f}\",\n",
    "        f\"{z_stat:.4f}\",\n",
    "        f\"{p_value:.6f}\",\n",
    "        'Yes' if p_value < 0.05 else 'No',\n",
    "        f\"{cohens_h:.4f}\",\n",
    "        f\"{current_power:.3f}\",\n",
    "        f\"{prob_test_worse:.3f}\"\n",
    "    ],\n",
    "    'Category': [\n",
    "        'Sample Size', 'Sample Size', 'Conversions', 'Conversions',\n",
    "        'Rate', 'Rate', 'Difference', 'Performance',\n",
    "        'Statistical Test', 'Statistical Test', 'Result', 'Effect',\n",
    "        'Power', 'Bayesian'\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# 2. Confidence Intervals Data\n",
    "ci_data = pd.DataFrame({\n",
    "    'Group': ['Control', 'Test'],\n",
    "    'Conversion_Rate': [control_rate, test_rate],\n",
    "    'Users': [control_users, test_users],\n",
    "    'Conversions': [control_conversions, test_conversions],\n",
    "    'CI_Lower': [control_ci[0], test_ci[0]],\n",
    "    'CI_Upper': [control_ci[1], test_ci[1]],\n",
    "    'CI_Width': [control_ci[1] - control_ci[0], test_ci[1] - test_ci[0]]\n",
    "})\n",
    "\n",
    "# 3. Sample Size Planning Data\n",
    "sample_size_scenarios = []\n",
    "baseline = control_rate\n",
    "scenarios = [\n",
    "    (\"10% Relative Improvement\", baseline * 1.1),\n",
    "    (\"20% Relative Improvement\", baseline * 1.2), \n",
    "    (\"50% Relative Improvement\", baseline * 1.5),\n",
    "    (\"Current Observed Difference\", test_rate)\n",
    "]\n",
    "\n",
    "for scenario, target_rate in scenarios:\n",
    "    if target_rate > 0:\n",
    "        n_needed = sample_size_calculator(baseline, target_rate)\n",
    "        sample_size_scenarios.append({\n",
    "            'Scenario': scenario,\n",
    "            'Target_Rate': target_rate,\n",
    "            'Required_Sample_Size': n_needed,\n",
    "            'Days_Needed': (n_needed * 2) / ((control_users + test_users) / 17)\n",
    "        })\n",
    "\n",
    "sample_size_df = pd.DataFrame(sample_size_scenarios)\n",
    "\n",
    "# 4. Business Impact Data\n",
    "business_impact = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Expected Conversions (if equal split)',\n",
    "        'Actual Test Conversions',\n",
    "        'Lost Conversions',\n",
    "        'Opportunity Cost %'\n",
    "    ],\n",
    "    'Value': [\n",
    "        expected_conversions_if_equal,\n",
    "        actual_test_conversions,\n",
    "        lost_conversions,\n",
    "        (lost_conversions/(control_conversions + test_conversions))*100\n",
    "    ]\n",
    "}) if test_users > control_users else pd.DataFrame({\n",
    "    'Metric': ['No business impact calculated - control had more users'],\n",
    "    'Value': [0]\n",
    "})\n",
    "\n",
    "# Export all files\n",
    "summary_df.to_csv(f'{output_dir}/ab_test_summary.csv', index=False)\n",
    "ci_data.to_csv(f'{output_dir}/confidence_intervals.csv', index=False)\n",
    "sample_size_df.to_csv(f'{output_dir}/sample_size_planning.csv', index=False)\n",
    "business_impact.to_csv(f'{output_dir}/business_impact.csv', index=False)\n",
    "\n",
    "print(\"âœ… Power BI data files created successfully!\")\n",
    "print(f\"ðŸ“‚ Files saved in: {output_dir}/\")\n",
    "print(\"   â€¢ ab_test_summary.csv - Key metrics and results\")\n",
    "print(\"   â€¢ confidence_intervals.csv - Statistical confidence data\")\n",
    "print(\"   â€¢ sample_size_planning.csv - Future test planning\")\n",
    "print(\"   â€¢ business_impact.csv - Business impact analysis\")\n",
    "\n",
    "print(\"\\nðŸ“Š Summary Data Preview:\")\n",
    "print(summary_df.head(10))\n",
    "\n",
    "print(\"\\nðŸ“ˆ Confidence Intervals Preview:\")\n",
    "print(ci_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
